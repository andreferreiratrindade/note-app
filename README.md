
# üöÄ Azure Serverless Processing with Storage Queue & Cosmos DB

## üìñ Overview

This project demonstrates a **serverless, decoupled, and scalable architecture** using Azure services. It consists of:

- An **API Gateway** that receives HTTP requests
- An **Azure Function (Producer)** that enqueues messages into an **Azure Storage Queue**
- A second **Azure Function (Consumer)** that processes the queued messages
- A **Cosmos DB** instance where the processed results are stored

This design enables asynchronous request handling and promotes scalability, cost-efficiency, and high availability.

---

## üß± Architecture Diagram

<img src="https://raw.githubusercontent.com/andreferreiratrindade/note-app/refs/heads/main/documents/diagram.png">


---

## üîß Components

| Component               | Description                                                                 |
|-------------------------|-----------------------------------------------------------------------------|
| **API Gateway**         | Receives external HTTP requests and routes them to the `enqueue` function   |
| **Function: Enqueue**   | Lightweight function that sends the request payload to the Storage Queue    |
| **Storage Queue**       | Durable queue for decoupling ingestion from processing                      |
| **Function: Process**   | Reads from the queue, performs business logic, and stores data in Cosmos DB |
| **Cosmos DB**           | NoSQL database used to persist the processed data                           |

---

## üî• Problems with a Purely Synchronous Architecture

In a **synchronous model**, the client sends a request and waits for the server to process everything before receiving a response. This might work well for small systems or low traffic, but it introduces serious challenges as load increases:

### ‚ùå 1. **Scalability Bottleneck**
- Each request ties up system resources (CPU, memory, threads) **until** the entire process finishes.
- If your process includes **slow operations** (e.g., complex business logic, DB writes, 3rd party API calls), it blocks the thread longer.
- Under high load, the app may **crash or become unresponsive**.

### ‚ùå 2. **User-Facing Latency**
- The user waits for the **entire chain** of operations to complete before getting a response.
- This increases **perceived latency**, hurting user experience.

### ‚ùå 3. **Reduced Resilience**
- A failure in any part of the flow causes the **entire request to fail**.
- No natural retry or buffering ‚Äî every failure impacts the user directly.

### ‚ùå 4. **Poor Load Spikiness Handling**
- No built-in mechanism to **absorb or delay processing** during spikes.
- Risk of overload and crash without expensive overprovisioning.

---

## ‚úÖ What This Architecture Solves

### ‚úÖ 1. **Asynchronous Request Handling**
- The API accepts the request and **quickly responds**, offloading the work to background processing.

### ‚úÖ 2. **Built-In Buffering via Queue**
- Azure Storage Queue acts as a **shock absorber**, smoothing spikes in traffic.
- No data loss or crash ‚Äî just delayed processing.

### ‚úÖ 3. **Elastic, Event-Driven Processing**
- Azure Functions **auto-scale** to match processing demand.

### ‚úÖ 4. **Improved Reliability and Fault Tolerance**
- Message retry on failure; durable queues.
- Dead-letter queues for unprocessable messages.

### ‚úÖ 5. **Decoupled Architecture = Maintainability**
- Each component has a **single responsibility**.
- Easier to evolve independently.

### ‚úÖ 6. **Cost-Effective**
- **Consumption-based pricing** ‚Äî you only pay when things are used.

---

## üß† Summary

| Scenario                        | Synchronous Approach                         | Async Architecture                             |
|--------------------------------|----------------------------------------------|------------------------------------------------|
| High request volume            | Risk of overload, timeouts                   | Queue absorbs load, functions scale            |
| Long processing time           | High latency for user                        | Fast response, async processing                |
| System failure during process  | User gets error                              | Message remains in queue, retry enabled        |
| Resource usage                 | Blocks threads and memory                    | Lightweight and event-driven                   |
| Cost                           | Needs overprovisioning for peak              | Pay-per-use, auto-scale                        |

---
